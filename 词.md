# 词

词是自然语言能够独立运用的最小单位，是自然语言处理的基本单位。从概念理解上来讲词是描述概念的最小单位。词语按一定规则的组合形成句子，也就是概念之间的组合形成更大的概念。对词法的分析包括词的形态分析（尤其是英语这类曲折语）、对词的分割、词性的分类等

## 英语的形态分析

英语中一个词在表达不同情况下有不同的形态，就比如单复数、时态变化和缩写等。对这类词形态的分析一般有两个基本方式，一个是对那些有较强变化规则的词用规则来分析，对规则不明显的采用词典来查找，如果两者都不属于则作为未登录词处理。

## 汉语的自动分词

不同于英语的空格存在，汉语词与词之间的界限并不明显，需要阅读者根据上下文和一定的规则来对词进行切分，因此如何将汉语自动分词是一个重要的问题。下面是一些汉语自动分词的基本算法：

### 最大匹配法

该方法包含正向最大匹配法、逆向最大匹配法和双向最大匹配法，并且需要词典的辅助来贪心选择当前最长的符合条件的分词。

算法的优点是实现起来比较简单，缺点是对词典的依赖非常大，而且最后分出来的效果不佳。

### 最少分词法（最短路径法）

利用词典将句子所有可能的分词作为图的节点，分词的前后相邻关系作为图的边，然后寻找从第一个分词到最后一个分词的最短路径，从而得到该句子最少的分词方法。这个算法建立的基础是人们总是倾向与用最少的话来将自己的意思表达清楚。

算法的优点是实现简单，缺点是计算量大，而且分词效果不佳。

### 基于隐马尔可夫（HMM）的分词算法

用概率的方法计算所有可能分词序列中概率最大的分词序列。设输入的句子为S，所有可能的分词为W，那么算法的目的是找到给定句子情况下概率最大的分词，用公式描述如下：

$$argmax_{W_i}P(W_i|S)$$

算法的优点是能够减少很多手工标注的工作量，在训练语料库规模足够大和覆盖领域足够多时可以获得较高的准确率。缺点是训练语料库的规模和覆盖领域不好把握，模型实现起来比较复杂，计算量比较大。

### 由字构词（基于字标注）的分词方法

基本思想为将分词过程看作字的分类问题，每个字要么是在词的开头或结尾，要么是在词的中间。因此整个过程变为对所有字进行归类。一种可行的算法是计算当前前后文下某个字作为词首、词尾、词中的概率，然后取其中的最大概率作为词的位置。可以利用支持向量机（SVM）和随机向量场（CRF）等工具来具体实现。

算法优点很明显能够平衡的看待词表中的词和未登录词的地位，因此可以大大简化了分词系统对未登录词的识别模块。该方法作为2002年的论文在2005年和2006年的两次Bakeoff评测中取得了好成绩。

### 生成模型和判别模型的方法结合

大部分基于词的分词方法采用的是生成式模型（Generative Model）。生成模型的特点是：假设o是观测值，q是模型，如果对$P(o|q)$进行建模，就是生成模型。基本步骤为首先建立样本的概率密度模型，再利用模型进行推理预测，要求已知样本无穷多或者尽可能的多，该方法一般建立在统计学和贝叶斯理论基础之上。能够从统计的角度表示数据的分布情况，能够反映同类数据本身的相似度。优点是相对判别模型有更丰富的信息，在研究单类问题比判别模型灵活性更强，而且模型可以通过增量学习得到，也能用于数据不完整（missing data）的情况。缺点是学习和计算的过程比较复杂。

而基于字的分词方法采用区分式（判别）模型（Discriminative Model）。判别模型的特点是：对条件概率（后验概率）$P(q|0)$进行建模，基本步骤是在有限样本上建立判别函数，不考虑样本的产生模型，直接研究预测模型，用到的理论是统计学习理论。目标是寻找不同类别之间的最优分类面，反应的数据之间的差异。有点是相对生成模型更容易学习。缺点是黑盒操作，变量间的关系不清楚，不可视。

在分词问题上将两种方法结合起来往往能够取得非常好的效果，结合的方法有：将判别模型和生成模型基元组合，然后利用生成模型求解；直接将判别模型和生成模型的结果用插值的方法结合起来。

### 分词结果评估

两种测试方法：

* 封闭测试/开放测试
* 专项测试/总体测试

分词结果评价方法：

* 正确率：$P=\frac{正确结果}{所有结果}\times100\%$
* 召回率（找回率）：$R=\frac{判断为正的正用例}{所有正用例}\times100\%$
* 精确率：$P=\frac{判断为正的正用例}{判断为正的所有用例}\times100\%$
* F-测试度(F-Measure)：正确率$P$和召回率$R$的综合值，计算公式为：$F-measure=\frac{(\beta^2+1)\times{P}\times{R}}{\beta^2\times{P}+R}\times100\%$，一般的β取值为1，即$F1=\frac{2\times{P}\times{R}}{P+R}\times100\%$

## 未登录词的识别

未登录词主要包括实体名词和新词，这些词由于不太可能用词典对其覆盖，所以需要额外的对待，针对具体情况具体分析。比如人名的识别需要将人名分词姓和名两部分来处理。

## 词性标注

汉语词性标注和词类划分主要面临的问题是消除词性兼类歧义。不同语言中，词性的划分基本已经约定俗成，并遵循以下原则：

* 标准性：普遍使用和认可的分类标准和符号集
* 兼容性：与已有的标记资源尽量保持一致，或可转换
* 可拓展性：扩充或修改

词性自动标注的方法主要有：

* 基于规则的词性标注方法
* 基于统计模型的词性标注方法
* 规则和统计模型相结合的词性标注方法
* 基于有限状态变换机的词性标注方法
* 基于神经网络的词性标注方法

## 基于规则的词性标注方法

手动编写词性标注规则

* TAGGIT词性标注系统（Brown University）
* 山西大学的词性标注系统

## 隐马尔可夫模型（Hidden Markov Model）

三个基本问题

* 给定观测序列$O=o_1,o_2,...,o_n$和模型$\lambda$，如何计算给定模型下观察序列$O$的概率$P(O|\lambda)$
* 给定一个观测序列$O=o_1,o_2,...,o_n$和模型$\lambda$，如何计算状态序列$Q=q_1,q_2,...,q_n$，使得该状态序列能够“最好的解释”观察序列
* 给定观察序列$O=o_1,o_2,...,o_n$，如何调节模型$\lambda$的参数值，使得$P(O|\lambda)最大

在词性分类的问题中要求解的就是给定词串$W$（观察序列）和模型$\lambda$，求使得条件概率$P(T|W,\lambda)$最大的词性串（状态序列）$T$。

$$T=argmax_T(P(T|W,\lambda))$$

又根据条件概率公式可得

$$P(T|W,\lambda)=\frac{P(T,W|\lambda)}{P(W|\lambda)}$$

因此有

$$P(T|W)=\frac{P(T,W)}{P(W)}=\frac{P(T)P(W|T)}{P(W)}$$
