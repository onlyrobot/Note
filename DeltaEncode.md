# 针对强化学习中连续数据设计的差分编码

## 背景

分布式强化学习涉及到大量的数据传输，主要有obs、action和model(weight)，些数据都具有很强的时间空间连续性，这为差分编码提供了可能性，而大规模分布式系统的性能瓶颈很多是网络，因此好的数据压缩算法能够一定程度上提高整体吞吐率。

在视频压缩中有很多可以借鉴成熟方案，比如预测编码、熵编码，一些数据库也包含了时间序列压缩算法，主要思想也是对前后数据的差分（或用前一数据预测后一数据）进行编码来减少数据量。

## 实现

差分编码首先计算前后数据之间的差分（Delta），再对该差分进行编码，解码时则根据该差分和之前的数据得到原数据。

强化学习中的数据类型可以分为浮点型和整型，整型数据间差分计算比较简单，直接相减即可，而浮点型存在阶码和尾数，在作减法操作时会涉及到对阶，因而难以在数据表示上看出差分，这里借鉴Gorilla time series compress中的算法，用两个浮点数之间的异或运算计算差分。

* 整型计算差分：
```none
last  = 0b0101010 10101010 10101010 101010101
cur   = 0b0101010 10101010 10101010 100010010
delta = cur - last 
      = 0b0000000 00000000 00000000 001000011
```
* 浮点数计算差分：
```none
last  = 0b0101010 10101010 10101010 101010101
cur   = 0b0101010 10101010 10101010 100010010
delta = cur ^ last 
      = 0b0000000 00000000 00000000 001000111
```

在前后数据“相差”不大的情况下，上面两种方法得到的差分都包含大量的前导零，使用基于bit的行程长度编码会大大减少数据长度。针对以上数据一个可行的方案是用5 bits(2^5=32)来记录前导零的数量，后面跟着其他非前导零bit串（有效串）。

* 整型差分编码前后
```none
delta = 0b0000000 00000000 00000000 001000011
coded = 0b0011110 00011
          ^^^^^-- -----
          5bits  7bits
```

* 浮点型差分编码前后
```none
delta = 0b0000000 00000000 00000000 001000111
coded = 0b0011110 00011
          ^^^^^-- -----
          5bits  7bits
```

解码时，需要提供last和coded，进行逆向操作。

为了进一步减少编码后的大小（降低编码率），有很多优化策略可以考虑，针对具体数据并权衡编码速率和编码率进行选择。

* 对二阶差分编码（即差分的差分）
* 采取变长的形式记录前导零数量（Huffman编码）
* 上面提到的有效串（除了前导零外的bit串）一定以1开头，因此可以在编码中去除。
* 除了前导零外还可以对后导零进行编码，Gorilla timer series compress中采取的对浮点数编码方式。

强化学习中的obs是多维数组，如同一帧图像，所有obs序列就像连续的视频；model也是多维数组，在训练的过程参数的变化也具有连续性，随着model的收敛，前后数据的delta也会越来越小。无论是obs还是model的连续性都非常强，适合用二阶差分编码，而后导零多存在规整的数据变化（比如0.5变为0.6），而分布式训练过程中的数据常常正则化、归零/一化，所以不宜采取。Huffman编码能够一定程度减少编码率，但是需要先统计全局的数据（或采样）进行Huffman编码树构造，而且需要额外的空间保存这棵树，也不宜采取。

在代码实现上综合了以上考虑以及执行效率进行了设计，编码和解码过程如下：

* 编码
```none
1. 输入：前一数据、当前数据、前一差分(last_delta)、bit输出流
2. 前后数据异或运算得到cur_delta
3. 计算cur_delta的前导零，如果前导零大于等于last_delta的前导零，转第4步，否则第5步
4. 向输出流输出flag 0，后面接着有效串，有效串的长度的占有长度为前一有效串长度（因为当前有效串长度小于等于上一有效串，所以肯定放的下），编码结束
5. 向输出流输出flag 1，后面接cur_delta的前导零数量和有效串，编码结束
```
* 解码
```none
1. 输入：前一数据、前一差分(last_delta)、bit输入流
2. 从输入流读取1位，如果是flag 0， 转第3步，否则第4步
3. 根据last_delat有效串长度从输入流读出有效串，得到cur_delta，并更新last_delta为cur_delta，转第5步
4. 从输入流读出有效串长度，再根据该长度读出有效串得到cur_delta, 并更新last_delta为cur_delta
5. 用cur_delat和前一数据异或运算得到当前数据，解码完成
```

## 评估

使用PPO算法对gym CartPole-v0进行训练，并对其中的obs(shape=(4,), dtype=float64)、action(shape=(1,), dtype=float64)、model(dtype=float64)进行编码（reward恒为1没有进行编码），编码率为90%、90%、75%，其中obs和action维度太低编码效果较差（编码掉的主要是阶码），在大规模环境多agent情况下可以预见会有大量数据前后变化较小，甚至很多数据保持不变。model的编码率则反映了梯度下降法训练的一般性，前后权重变化和学习率以及epoche有关，在前期权重变化较大，编码率在80%左右，随着模型的收敛最后能达到70%左右。

在编码速率上和lz4压缩算法进行了简单对比，预估在同一数量级。

更多的评估有待进行。

## 应用

* Learner Worker在通过网络publish weight之前可以利用上一次的weight进行差分编码，Predictor Worker则根据上一weight解码。
* Actor Worker在和Predictor和ReplayBuffer通信的时候可以先将前后的obs/action进行差分编码，再压缩，从而提高整体的压缩率。

注意：编码和解码的过程中都依赖之前的数据，所以需要避免来自不同Worker的数据混淆，以及在错误发生时及时恢复。
